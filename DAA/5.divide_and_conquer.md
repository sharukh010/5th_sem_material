### Divide & Conquer Algorithms

**Divide and Conquer** is a powerful algorithm design paradigm based on multi-branched recursion. A divide-and-conquer algorithm works by recursively breaking down a problem into two or more sub-problems of the same or related type until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.

#### Structure of Divide-and-Conquer Algorithms

1. **Divide**: Break the problem into several sub-problems that are smaller instances of the same problem.
2. **Conquer**: Solve the sub-problems recursively. If the sub-problems are small enough, solve them directly.
3. **Combine**: Combine the solutions of the sub-problems to form the solution to the original problem.

### Examples of Divide & Conquer Algorithms

#### 1. Binary Search

**Definition**: Binary Search is a searching algorithm that finds the position of a target value within a sorted array.

**Algorithm**:
```cpp
int binarySearch(int arr[], int l, int r, int x) {
    if (r >= l) {
        int mid = l + (r - l) / 2;
        
        if (arr[mid] == x)
            return mid;

        if (arr[mid] > x)
            return binarySearch(arr, l, mid - 1, x);
        
        return binarySearch(arr, mid + 1, r, x);
    }
    return -1;
}
```

**Analysis**:
- **Time Complexity**: $$O(\log n)$$
- **Space Complexity**: $$O(\log n)$$ for recursive implementation, $$O(1)$$ for iterative implementation.

#### 2. Quick Sort

**Definition**: Quick Sort is a highly efficient sorting algorithm that follows the divide-and-conquer approach.

**Algorithm**:
```cpp
int partition(int arr[], int low, int high) {
    int pivot = arr[high];
    int i = (low - 1);
    for (int j = low; j <= high - 1; j++) {
        if (arr[j] < pivot) {
            i++;
            std::swap(arr[i], arr[j]);
        }
    }
    std::swap(arr[i + 1], arr[high]);
    return (i + 1);
}

void quickSort(int arr[], int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
```

**Analysis**:
- **Best Case Time Complexity**: $$O(n \log n)$$
- **Average Case Time Complexity**: $$O(n \log n)$$
- **Worst Case Time Complexity**: $$O(n^2)$$ - This occurs when the smallest or largest element is always chosen as the pivot.
- **Space Complexity**: $$O(\log n)$$

#### 3. Merge Sort

**Definition**: Merge Sort is a stable, comparison-based, and divide-and-conquer sorting algorithm.

**Algorithm**:
```cpp
void merge(int arr[], int l, int m, int r) {
    int n1 = m - l + 1;
    int n2 = r - m;

    int L[n1], R[n2];
    for (int i = 0; i < n1; i++)
        L[i] = arr[l + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[m + 1 + j];

    int i = 0, j = 0, k = l;
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }

    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }

    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
}

void mergeSort(int arr[], int l, int r) {
    if (l < r) {
        int m = l + (r - l) / 2;
        mergeSort(arr, l, m);
        mergeSort(arr, m + 1, r);
        merge(arr, l, m, r);
    }
}
```

**Analysis**:
- **Time Complexity**: $$O(n \log n)$$ in all cases.
- **Space Complexity**: $$O(n)$$

#### 4. Strassen Multiplication

**Definition**: Strassen's Algorithm is used for matrix multiplication and is more efficient than the standard matrix multiplication algorithm.
x
### Strassen's Matrix Multiplication Formulas

Strassen's algorithm is a method to multiply two $$n \times n$$ matrices that is more efficient than the standard algorithm. For simplicity, let's consider two $$2 \times 2$$ matrices. Strassen's algorithm reduces the number of multiplications needed from 8 to 7, improving the time complexity for large matrices.

Given two matrices $$A$$ and $$B$$:

$$ A = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}, \quad B = \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix} $$

Strassen's algorithm computes the following 7 products (often called $$M_1$$ to $$M_7$$):

1. $$M_1 = (a_{11} + a_{22})(b_{11} + b_{22})$$
2. $$M_2 = (a_{21} + a_{22}) b_{11}$$
3. $$M_3 = a_{11} (b_{12} - b_{22})$$
4. $$M_4 = a_{22} (b_{21} - b_{11})$$
5. $$M_5 = (a_{11} + a_{12}) b_{22}$$
6. $$M_6 = (a_{21} - a_{11}) (b_{11} + b_{12})$$
7. $$M_7 = (a_{12} - a_{22}) (b_{21} + b_{22})$$

Using these products, we can compute the elements of the resulting matrix $$C$$ as follows:

$$ C = \begin{bmatrix} c_{11} & c_{12} \\ c_{21} & c_{22} \end{bmatrix}$$

where:

1. $$c_{11} = M_1 + M_4 - M_5 + M_7$$
2. $$c_{12} = M_3 + M_5$$
3. $$c_{21} = M_2 + M_4$$
4. $$c_{22} = M_1 - M_2 + M_3 + M_6$$

### Example

Consider two matrices:

$$ A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}, \quad B = \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} $$

First, compute the seven products:

1. $$M_1 = (1 + 4)(5 + 8) = 5 \times 13 = 65$$
2. $$M_2 = (3 + 4) \times 5 = 7 \times 5 = 35$$
3. $$M_3 = 1 \times (6 - 8) = 1 \times (-2) = -2$$
4. $$M_4 = 4 \times (7 - 5) = 4 \times 2 = 8$$
5. $$M_5 = (1 + 2) \times 8 = 3 \times 8 = 24$$
6. $$M_6 = (3 - 1) \times (5 + 6) = 2 \times 11 = 22$$
7. $$M_7 = (2 - 4) \times (7 + 8) = -2 \times 15 = -30$$

Next, compute the elements of the resulting matrix:

1. $$c_{11} = M_1 + M_4 - M_5 + M_7 = 65 + 8 - 24 - 30 = 19$$
2. $$c_{12} = M_3 + M_5 = -2 + 24 = 22$$
3. $$c_{21} = M_2 + M_4 = 35 + 8 = 43$$
4. $$c_{22} = M_1 - M_2 + M_3 + M_6 = 65 - 35 - 2 + 22 = 50$$

Therefore, the resulting matrix $$C$$ is:

$$ C = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix} $$

### Summary

Strassen's algorithm for matrix multiplication efficiently reduces the number of multiplications required. The core of the algorithm involves calculating 7 intermediate products and using them to construct the final product matrix:

$$ M_1 = (a_{11} + a_{22})(b_{11} + b_{22}) $$
$$ M_2 = (a_{21} + a_{22}) b_{11} $$
$$ M_3 = a_{11} (b_{12} - b_{22}) $$
$$ M_4 = a_{22} (b_{21} - b_{11}) $$
$$ M_5 = (a_{11} + a_{12}) b_{22} $$
$$ M_6 = (a_{21} - a_{11}) (b_{11} + b_{12}) $$
$$ M_7 = (a_{12} - a_{22}) (b_{21} + b_{22}) $$

$$ c_{11} = M_1 + M_4 - M_5 + M_7 $$
$$ c_{12} = M_3 + M_5 $$
$$ c_{21} = M_2 + M_4 $$
$$ c_{22} = M_1 - M_2 + M_3 + M_6 $$

This method improves the efficiency of matrix multiplication, especially for large matrices.


**Algorithm**:
For two $$2 \times 2$$ matrices, the Strassen's algorithm reduces the multiplication to seven multiplications and 18 additions/subtractions.

1. Divide each matrix into four sub-matrices.
2. Apply Strassen's formulas to get the product sub-matrices.
3. Combine these sub-matrices to get the final product matrix.

**Analysis**:
- **Time Complexity**: $$O(n^{\log_2 7}) \approx O(n^{2.81})$$
- **Space Complexity**: $$O(n^2)$$

#### 5. Max-Min Problem

**Definition**: The Max-Min problem involves finding both the maximum and minimum elements in an array.

**Algorithm**:
Using the divide-and-conquer approach:
```cpp
struct Pair {
    int min;
    int max;
};

Pair getMinMax(int arr[], int low, int high) {
    Pair minmax, mml, mmr;
    int mid;

    if (low == high) {
        minmax.max = arr[low];
        minmax.min = arr[low];
        return minmax;
    }

    if (high == low + 1) {
        if (arr[low] > arr[high]) {
            minmax.max = arr[low];
            minmax.min = arr[high];
        } else {
            minmax.max = arr[high];
            minmax.min = arr[low];
        }
        return minmax;
    }

    mid = (low + high) / 2;
    mml = getMinMax(arr, low, mid);
    mmr = getMinMax(arr, mid + 1, high);

    minmax.min = (mml.min < mmr.min) ? mml.min : mmr.min;
    minmax.max = (mml.max > mmr.max) ? mml.max : mmr.max;

    return minmax;
}
```

**Analysis**:
- **Time Complexity**: $$O(n)$$
- **Space Complexity**: $$O(\log n)$$ for the recursive stack space.

### Summary

**Divide and Conquer** algorithms follow a pattern of breaking a problem into sub-problems, solving these recursively, and combining their solutions. Examples include:

1. **Binary Search**: Efficient search with $$O(\log n)$$ time complexity.
2. **Quick Sort**: Efficient sorting, though worst-case $$O(n^2)$$ but average-case $$O(n \log n)$$.
3. **Merge Sort**: Stable, consistent $$O(n \log n)$$ sorting.
4. **Strassen Multiplication**: More efficient matrix multiplication with $$O(n^{2.81})$$.
5. **Max-Min Problem**: Efficiently finding max and min in $$O(n)$$ time.

Understanding these algorithms will provide a strong foundation in solving problems using the divide-and-conquer paradigm and help you in your descriptive exam.